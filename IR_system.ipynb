{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure out how to filter similar nba players by position\n",
    "\n",
    "try to make good/great amplify the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind_to_prospect = {}\n",
    "prospect_to_ind = {}\n",
    "prospects = []\n",
    "with open(\"prospect_to_docs.json\") as f:\n",
    "    for l in f:\n",
    "        line = json.loads(l)\n",
    "        for ind, (prospect, text) in enumerate(line.items()):\n",
    "            ind_to_prospect[ind] = prospect\n",
    "            prospect_to_ind[prospect] = ind\n",
    "            prospects.append(text)\n",
    "with open(\"prospect_to_position.json\") as f:\n",
    "    for l in f:\n",
    "        prospect_to_position = json.loads(l)\n",
    "        \n",
    "            \n",
    "ind_to_player = {}\n",
    "player_to_ind = {}\n",
    "players = []\n",
    "with open(\"curr_player_to_docs.json\") as f:\n",
    "    for l in f:\n",
    "        line = json.loads(l)\n",
    "        for ind, (player, text) in enumerate(line.items()):\n",
    "            ind_to_player[ind] = player\n",
    "            player_to_ind[player] = ind\n",
    "            players.append(text)\n",
    "with open(\"curr_player_to_position.json\") as f:\n",
    "    for l in f:\n",
    "        player_to_position = json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = []\n",
    "    for tok in tokens:\n",
    "        try:\n",
    "            i = int(tok)\n",
    "            stems.append(num2words(i))\n",
    "        except ValueError:\n",
    "            stems.append(stemmer.stem(tok))\n",
    "    #stems = [stemmer.stem(token) for token in tokens]\n",
    "    return stems\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", tokenizer=tokenize, ngram_range=(1, 3), norm=None)\n",
    "docs = tfidf.fit(players+prospects)\n",
    "prospect_docs = tfidf.transform(prospects).toarray()\n",
    "player_docs = tfidf.transform(players).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_similarity(query, topk=10):\n",
    "    transformed = tfidf.transform([query]).toarray().flatten()\n",
    "    sims = []\n",
    "    for ind, row in enumerate(prospect_docs):\n",
    "        doc = row.flatten()\n",
    "        if not np.all(doc == 0.0):\n",
    "            dotted = np.dot(doc, transformed)\n",
    "            sim = dotted/(np.linalg.norm(doc)*np.linalg.norm(transformed))\n",
    "            sims.append((sim, ind_to_prospect[ind]))\n",
    "    sorted_sims = sorted(sims, key=lambda x:x[0], reverse=True)\n",
    "    print query\n",
    "    for i in range(1, topk + 1):\n",
    "        out = sorted_sims[i-1]\n",
    "        print(\"Rank {}: {}, Similarity: {}\".format(i, out[1], out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good shooter\n",
      "Rank 1: De Aaron Fox, Similarity: 0.0233413987502\n",
      "Rank 2: Josh Jackson, Similarity: 0.0191884595667\n",
      "Rank 3: Tadas Sedekerskis, Similarity: 0.0175138930938\n",
      "Rank 4: L.J. Peak, Similarity: 0.0168032821348\n",
      "Rank 5: Kostja Mushidi, Similarity: 0.0152005432887\n",
      "Rank 6: Jayson Tatum, Similarity: 0.013720729488\n",
      "Rank 7: Sviatoslav Mykhailiuk, Similarity: 0.0123916783659\n",
      "Rank 8: Joel Berry, Similarity: 0.012224693362\n",
      "Rank 9: Markelle Fultz, Similarity: 0.0121713798878\n",
      "Rank 10: Luke Kennard, Similarity: 0.0120992872442\n"
     ]
    }
   ],
   "source": [
    "find_similarity(\"good shooter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_similar_players(prospect, topk=10):\n",
    "    if prospect not in prospect_to_ind:\n",
    "        print \"Not a valid prospect\"\n",
    "        return\n",
    "    prospect_position = prospect_to_position[prospect]\n",
    "    prospect_ind = prospect_to_ind[prospect]\n",
    "    prospect_doc = prospect_docs[prospect_ind]\n",
    "    sims = []\n",
    "    for ind, row in enumerate(player_docs):\n",
    "        name = ind_to_player[ind]\n",
    "        position = player_to_position[name]\n",
    "        if position in prospect_position:\n",
    "            doc = row.flatten()\n",
    "            if not np.all(doc == 0.0):\n",
    "                dotted = np.dot(doc, prospect_doc)\n",
    "                sim = dotted/(np.linalg.norm(doc)*np.linalg.norm(prospect_doc))\n",
    "                sims.append((sim, name))\n",
    "    sorted_sims = sorted(sims, key=lambda x:x[0], reverse=True)\n",
    "    print prospect\n",
    "    for i in range(1, topk + 1):\n",
    "        out = sorted_sims[i-1]\n",
    "        print(\"Rank {}: {}, Similarity: {}\".format(i, out[1], out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T.J. Leaf\n",
      "Rank 1: Kevin Love, Similarity: 0.151849132784\n",
      "Rank 2: Michael Beasley, Similarity: 0.137175016199\n",
      "Rank 3: Patrick Patterson, Similarity: 0.134354747327\n",
      "Rank 4: Terrence Jones, Similarity: 0.132819374028\n",
      "Rank 5: Lavoy Allen, Similarity: 0.132630150865\n",
      "Rank 6: Corey Jefferson, Similarity: 0.131583955235\n",
      "Rank 7: Tyrus Thomas, Similarity: 0.131522765797\n",
      "Rank 8: Ersan Ilyasova, Similarity: 0.131161698537\n",
      "Rank 9: Trevor Booker, Similarity: 0.131087866562\n",
      "Rank 10: Joe Alexander, Similarity: 0.131085314408\n"
     ]
    }
   ],
   "source": [
    "find_similar_players(\"T.J. Leaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He does not have an innate sense for how to create high percentage looks for himself at this stage, which is compounded by his struggles as a perimeter shooter, as he often settles for difficult floaters around or outside the paint, which he finds mixed results with.As a shooter, Fox does not have bad mechanics, but struggles to translate that to game settings at the moment.\n",
      "compound: -0.5065, \n",
      "neg: 0.098, \n",
      "neu: 0.852, \n",
      "pos: 0.05, \n",
      "With that said, his struggles as a scorer will make it easier for defenses to game plan against him if he isn't able to improve as a finisher and shooter, particularly in late clock situations.\n",
      "compound: -0.1043, \n",
      "neg: 0.128, \n",
      "neu: 0.755, \n",
      "pos: 0.117, \n",
      "Not a good shooter at all.\n",
      "compound: 0.4404, \n",
      "neg: 0.0, \n",
      "neu: 0.58, \n",
      "pos: 0.42, \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "with open(\"prospect_to_docs.json\") as f:\n",
    "    for l in f:\n",
    "        line = json.loads(l)\n",
    "        text = line[\"De Aaron Fox\"]\n",
    "        sents = sent_tokenize(text)\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        for sent in sents:\n",
    "            if \"shoot\" in sent:\n",
    "                print sent\n",
    "                ss = sid.polarity_scores(sent)\n",
    "                for k in sorted(ss):\n",
    "                    print('{0}: {1}, '.format(k, ss[k]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
